{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KBwI5b0dt76X"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "%matplotlib inline\n",
    "import shim as ced\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WvYzICYMuJB8"
   },
   "outputs": [],
   "source": [
    "# Loading the data from the drive and saving it to Categories\n",
    "DATADIR =\"C:/study_material/capp/retina/1 vs 2,3,4\"\n",
    "CATEGORIES = ['1','2,3,4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shim_1 import *\n",
    "IMG_SIZE=224\n",
    "img_r=[]\n",
    "y_train=[]\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR,category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    imgs = load_data(path)\n",
    "    for i in imgs:\n",
    "        a= cv2.resize(i,(IMG_SIZE,IMG_SIZE))\n",
    "        img_r.append(a)\n",
    "        y_train.append(class_num)\n",
    "\n",
    "detector = ced.cannyEdgeDetector(img_r, sigma=1.4, kernel_size=5, lowthreshold=0.071, highthreshold=0.12, weak_pixel=100)\n",
    "imgs_final = detector.detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "a=np.array(imgs_final)\n",
    "for image in a:\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    x1 = image.shape[0]\n",
    "    x2 = image.shape[1]\n",
    "    image = tf.reshape(tf.broadcast_to(image, (x1, x2, 3)),  (x1, x2, 3))\n",
    "    X_train.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IaFQd-r0yZDR"
   },
   "outputs": [],
   "source": [
    "# normalising the data\n",
    "X_train = np.array(X_train)/255\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2386, 224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2386,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laoding Val_Test data\n",
    "DATADIR =\"C:/study_material/capp/retina/Val_Test(1 vs 234)\"\n",
    "CATEGORIES = ['1','2,3,4']\n",
    "\n",
    "from shim_1 import *\n",
    "IMG_SIZE=224\n",
    "img_r=[]\n",
    "y_test=[]\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR,category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    imgs = load_data(path)\n",
    "    for i in imgs:\n",
    "        a= cv2.resize(i,(IMG_SIZE,IMG_SIZE))\n",
    "        img_r.append(a)\n",
    "        y_test.append(class_num)\n",
    "\n",
    "detector = ced.cannyEdgeDetector(img_r, sigma=1.4, kernel_size=5, lowthreshold=0.071, highthreshold=0.12, weak_pixel=100)\n",
    "imgs_final = detector.detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists to append images and labels\n",
    "X_test=[]\n",
    "a=np.array(imgs_final)\n",
    "for image in a:\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    x1 = image.shape[0]\n",
    "    x2 = image.shape[1]\n",
    "    image = tf.reshape(tf.broadcast_to(image, (x1, x2, 3)),  (x1, x2, 3))\n",
    "    X_test.append(image)\n",
    "\n",
    "\n",
    "\n",
    "# converting the train and test data into arrays\n",
    "X_test = np.array(X_test)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
    "                                include_top = False, # Leave out the last fully connected layer\n",
    "                                weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_output = pre_trained_model.output\n",
    "x=layers.GlobalAveragePooling2D()(last_output)\n",
    "# Flatten the output layer to 1 dimension\n",
    "#x = layers.Flatten()(x)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='tanh')(x)\n",
    "\n",
    "# Add a dropout rate of 0.2\n",
    "#x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "cnn = Model( pre_trained_model.input, x) \n",
    "\n",
    "cnn.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "kRVu9BB5ytp4",
    "outputId": "4756efbf-3229-4c11-ec95-d1bdf7619772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "75/75 [==============================] - 669s 9s/step - loss: 0.6429 - acc: 0.6429\n",
      "Epoch 2/20\n",
      "75/75 [==============================] - 652s 9s/step - loss: 0.6036 - acc: 0.6995\n",
      "Epoch 3/20\n",
      "75/75 [==============================] - 653s 9s/step - loss: 0.5725 - acc: 0.7179\n",
      "Epoch 4/20\n",
      "75/75 [==============================] - 669s 9s/step - loss: 0.5577 - acc: 0.7293\n",
      "Epoch 5/20\n",
      "75/75 [==============================] - 678s 9s/step - loss: 0.5204 - acc: 0.7552\n",
      "Epoch 6/20\n",
      "75/75 [==============================] - 567s 8s/step - loss: 0.5054 - acc: 0.7586\n",
      "Epoch 7/20\n",
      "75/75 [==============================] - 568s 8s/step - loss: 0.4760 - acc: 0.7854\n",
      "Epoch 8/20\n",
      "75/75 [==============================] - 582s 8s/step - loss: 0.4638 - acc: 0.7896\n",
      "Epoch 9/20\n",
      "75/75 [==============================] - 583s 8s/step - loss: 0.4420 - acc: 0.8051\n",
      "Epoch 10/20\n",
      "75/75 [==============================] - 648s 9s/step - loss: 0.4302 - acc: 0.8198\n",
      "Epoch 11/20\n",
      "75/75 [==============================] - 680s 9s/step - loss: 0.3935 - acc: 0.8324\n",
      "Epoch 12/20\n",
      "75/75 [==============================] - 660s 9s/step - loss: 0.3745 - acc: 0.8437\n",
      "Epoch 13/20\n",
      "75/75 [==============================] - 584s 8s/step - loss: 0.3376 - acc: 0.8575\n",
      "Epoch 14/20\n",
      "75/75 [==============================] - 559s 7s/step - loss: 0.3170 - acc: 0.8663\n",
      "Epoch 15/20\n",
      "75/75 [==============================] - 559s 7s/step - loss: 0.2755 - acc: 0.8801\n",
      "Epoch 16/20\n",
      "75/75 [==============================] - 557s 7s/step - loss: 0.2448 - acc: 0.8961\n",
      "Epoch 17/20\n",
      "75/75 [==============================] - 673s 9s/step - loss: 0.2108 - acc: 0.9174\n",
      "Epoch 18/20\n",
      "75/75 [==============================] - 660s 9s/step - loss: 0.1888 - acc: 0.9246\n",
      "Epoch 19/20\n",
      "75/75 [==============================] - 656s 9s/step - loss: 0.1708 - acc: 0.9380\n",
      "Epoch 20/20\n",
      "75/75 [==============================] - 676s 9s/step - loss: 0.1434 - acc: 0.9464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15e09d33130>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(np.array(X_train), np.array(y_train), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('sg_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KjzUb3L5yvmu",
    "outputId": "12614546-9f73-4a95-9180-aa52b6b68f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 15s 2s/step - loss: 1.1430 - acc: 0.6857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1430062055587769, 0.6857143044471741]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(np.array(X_test),np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LJhtxc3Uyx5r",
    "outputId": "d1ded5f3-4a39-49b1-ab2a-c126ac4d1a6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47761655],\n",
       "       [0.0809128 ],\n",
       "       [0.11020881],\n",
       "       [0.00261593],\n",
       "       [0.02425665],\n",
       "       [0.59811187],\n",
       "       [0.50462455],\n",
       "       [0.11930764],\n",
       "       [0.00644857],\n",
       "       [0.00819987],\n",
       "       [0.7583698 ],\n",
       "       [0.00135016],\n",
       "       [0.20106345],\n",
       "       [0.00491241],\n",
       "       [0.01110217],\n",
       "       [0.48705393],\n",
       "       [0.01762554],\n",
       "       [0.44812894],\n",
       "       [0.79558814],\n",
       "       [0.00353453]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ua06PVPkRzV4",
    "outputId": "b086d6ce-c684-4858-c55f-b35b7f62b4c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.78      0.43        27\n",
      "           1       0.94      0.67      0.78       148\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.62      0.72      0.61       175\n",
      "weighted avg       0.84      0.69      0.73       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import numpy as np\n",
    "y_pred = cnn.predict(X_test)\n",
    "y_pred_class=[]\n",
    "for i in y_pred:\n",
    "    if i>0.5:\n",
    "        y_pred_class.append(1)\n",
    "    else:\n",
    "        y_pred_class.append(0) \n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      " [[21  6]\n",
      " [49 99]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report: \\n\", confusion_matrix(y_test, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
